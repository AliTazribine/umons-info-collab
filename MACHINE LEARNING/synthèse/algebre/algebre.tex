\section{Algèbre linéaire}
    Nous donnons ici quelques formules qui pourraient être utiles. Des définitions complémentaires peuvent être trouvées dans le reste du document (comme la définition des valeurs propres). Les définitions et formules proviennent principalement de Wikipédia.

    \subsection{Signe de la dérivée seconde et maximum/minimum}
        Un point \(x\) d'une fonction \(f\) est un \textit{minimum} si \(f'(x) = 0\) et \(f''(x) > 0\).

        Un point \(x\) d'une fonction \(f\) est un \textit{maximum} si \(f'(x) = 0\) et \(f''(x) < 0\).

    \subsection{Vecteurs}
        \begin{definition}
            Soit \(q \geq 1\). La \textit{q-norme}\index{Norme} d'un vecteur \(x = (x_1, \dots, x_p)\) est
            \[
                \norm{x}_q = \left(\sum_{j=1}^p |x_j|^q\right)^{\frac{1}{q}}
            \]

            Quelques normes particulières :
            \begin{itemize}
                \item \(q = 1\): norme \(L_1\) (terme pénalisant de la régression Lasso)
                \item \(q = 2\): norme \(L_2\), norme euclidienne (terme pénalisant de la régression Ridge)
                \item \(q = \infty\): norme \(L_\infty\), norme uniforme :
                \[
                    \norm{x}_\infty = \max\{|x_1|, \dots, |x_p|\}
                \]
            \end{itemize}
        \end{definition}

        \begin{definition}
            Le \textit{produit scalaire} de deux vecteurs \(x, y \in \R^n\) est :
            \begin{align*}
                xy &= \norm{x}_2 \norm{y}_2 \cos(\theta) & \theta \text{ est l'angle entre \(x\) et \(y\)} \\
                &= \sum_{i=1}^n x_i y_i
            \end{align*}

            On peut aussi voir le produit scalaire comme un produit de deux matrices. Si on considère les deux vecteurs comme étant des vecteurs colonnes, le produit scalaire est donné par \(xy^T\).

            Le produit scalaire est commutatif et distributif.
        \end{definition}

        \begin{definition}
            Un vecteur est dit \textit{unitaire} si sa 2-norme vaut 1.

            Deux vecteurs \(x\) et \(y\) sont \textit{orthogonaux} si leur produit scalaire est nul, c'est-à-dire si \(u v = 0\).

            Deux vecteurs sont \textit{orthonormaux} s'ils sont unitaires et orthogonaux.
        \end{definition}

        \begin{definition}
            Deux vecteurs \(x, y \in \R^n\) sont \textit{linéairement dépendants} si l'un peut être exprimé comme une combinaison linéaire de l'autre, c'est-à-dire s'il existe deux scalaires \(a_1, a_2\) (non tous deux nuls, c'est-à-dire \(a_1 \not= 0 \lor a_2 \not= 0\)) tels que \(a_1 x + a_2 y = 0\) (où \(0\) est le vecteur nul).

            Deux vecteurs sont \textit{linéairement indépendants} s'ils ne sont pas linéairement dépendants.
        \end{definition}

    \subsection{Matrices}
        \begin{definition}
            Le \textit{rang} d'une matrice est le nombre de colonnes linéairement indépendantes.
        \end{definition}

        \begin{definition}
            La \textit{trace} d'une matrice carrée \(A \in \R^{n\times n}\) est 
            \[
                \trace(A) = \sum_{i=1}^n a_{ii}
            \]
        \end{definition}

        \begin{propriete}
            Soient \(A \in \R^{n \times p}, B \in \R^{p\times n}\). On a:
            \[
                \trace(AB) = \trace(BA)
            \]
        \end{propriete}

        \begin{definition}
            Le \textit{produit} de deux matrices \(A \in \R^{n \times m}, B \in \R^{m \times p}\) est la matrice \(C \in \R^{n \times p}\) telle que
            \[
                \forall i \in \{1, \dots, n\}, \forall j \in \{1, \dots, p\}, c_{ij} = \sum_{k=1}^m a_{ik} b_{kj}
            \]

            Le produit matriciel n'est pas commutatif mais est distributif et associatif.

            On a :
            \[
                (AB)^T = B^T A^T
            \]
        \end{definition}
        
        \subsection{Inverse}
            \begin{definition}
                Une matrice \(A \in \R^{n \times n}\) est dite \textit{inversible} (ou \textit{non-singulière}) si et seulement si (les conditions suivantes sont équivalentes) :
                \begin{itemize}
                    \item Son déterminant est non-nul.
                    \item Il existe une unique matrice \(B \in \R^{n \times n}\) telle que \(AB = BA = \identity_n\). \(B\) est appelé l'\textit{inverse} de \(A\) et est souvent notée \(A^{-1}\)
                    \item 0 n'est pas une valeur propre de \(A\)
                    \item Le rang de la matrice est \(n\)
                \end{itemize}
            \end{definition}

            \begin{propriete}
                On a les propriétés suivantes :
                \begin{align*}
                    (A^{-1})^{-1} &= A\\
                    \forall k \in \R\setminus\{0\}, (kA)^{-1} &= k^{-1}A^{-1}\\
                    (A^T)^{-1} &= (A^{-1})^T\\
                    \det(A^{-1}) &= (\det(A))^{-1}\\
                    (AB)^{-1} &= (B^{-1} A^{-1})
                \end{align*}
            \end{propriete}

            \subsubsection{Calculs}
                Nous donnons ici quelques formules pour calculer l'inverse d'une matrice (les formules qui semblent les plus utiles vu le reste du cours).

                \paragraph{Décomposition en valeurs propres}
                    Si une matrice peut être décomposée en valeurs propres, c'est-à-dire si on peut écrire \(A = Q \Lambda Q^T\), alors \(A\) est inversible et son inverse est donnée par :
                    \[
                        A^{-1} = Q \Lambda^{-1} Q^{-1}
                    \]
                    L'inverse de \(\Lambda\) est simple à calculer car \(\Lambda\) est une matrice diagonale.

                \paragraph{Solution analytique}
                    \begin{definition}
                        Le \textit{cofacteur} d'indice \(i,j\) de \(A\in\R^{n\times n}\) est :
                        \[
                            C_{ij} = (-1)^{i+j} \det(A_{i,j})
                        \]
                        où \(A_{i,j}\) est la sous-matrice carrée de taile \(n-1\) déduite de \(A\) en supprimant la \(i\)\ieme{} ligne et la \(j\)\ieme{} colonne.
                    \end{definition}

                    Soit \(C\), la matrice des cofacteurs de \(A\). Alors,
                    \begin{align*}
                        A^{-1} &= \frac{1}{\det(A)} C^T\\
                        (A^{-1})_{ij} &= \frac{1}{\det(A)} (C_{ji})
                    \end{align*}

                \paragraph{Matrice \(2 \times 2\)}
                    En utilisant les cofacteurs, on obtient :
                    \[
                        A^{-1} = \begin{pmatrix}
                            a & b\\
                            c & d
                        \end{pmatrix}^{-1} = \frac{1}{ad - bc} \begin{bmatrix}
                            d & -b\\
                            -c & a
                        \end{bmatrix}
                    \]